{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c2f82ad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install requirements prior to running this notebook (instructions in read.me)\n",
    "\n",
    "# Run Imports\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1602650",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Intialise MediaPipe Pose setup\n",
    "mp_pose = mp.solutions.pose   # mp.solutions.pose is a module that handles human pose detection. mp_pose is just shorthand\n",
    "pose = mp_pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5)   # Pose() creates a pose object that does the detection. Can pass parameters to Pose() to aid detection\n",
    "mp_draw = mp.solutions.drawing_utils   # drawing_utils is helper module that can draw landmarks and connections on images (visualisation tool)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6d6911d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Viraj\\_Personal Docs\\__Work\\11 Fall 2025\\_ME6705 Mechatronics\\Final Project\\_CODE\\venv\\Lib\\site-packages\\google\\protobuf\\symbol_database.py:55: UserWarning: SymbolDatabase.GetPrototype() is deprecated. Please use message_factory.GetMessageClass() instead. SymbolDatabase.GetPrototype() will be removed soon.\n",
      "  warnings.warn('SymbolDatabase.GetPrototype() is deprecated. Please '\n"
     ]
    }
   ],
   "source": [
    "# start webcam\n",
    "cap = cv2.VideoCapture(0)  # (0 = default webcam. This can be 0, 1, 2, etc. depending on the number of cameras)\n",
    "# cap is now an object that will grab frames one by one\n",
    "\n",
    "while True:   # inf loop to keep reading\n",
    "\n",
    "    ret, frame = cap.read()  # read() captures a frame from the webcam\n",
    "    # ret -> boolean. True if a frame was sucessfully captured\n",
    "    # frame is the image aarray (height x width x 3 colour channels)\n",
    "    if not ret:  \n",
    "        break  # if ret is False, exit loop (smth went wrong)\n",
    "\n",
    "\n",
    "    # Convert BGR (OpenCV) to RGB (MediaPipe)\n",
    "     # OpenCV reads immages in BGR colours but Media Pipe expects RGB\n",
    "    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "\n",
    "    # Process frame with MediaPipe Pose\n",
    "    # process() passes the RGB Frame to the MediaPipe Pose Detector\n",
    "    # reults contains all detected pose landmarks and tracking information\n",
    "    results = pose.process(rgb_frame)\n",
    "\n",
    "    # results.pose_landmarks() holds all the keypoints. (elbows, shoulders, hips, etc.) \n",
    "    # if a person is detected\n",
    "    image = frame\n",
    "    # Draw skeleton if pose detected (if a person is detected)\n",
    "    if results.pose_landmarks:\n",
    "        mp_draw.draw_landmarks(image, results.pose_landmarks, mp_pose.POSE_CONNECTIONS)\n",
    "        # draw_landmarks draws small dots for keypoints and connections (lines connecting joints according to mp_pose.CONNECTIONS)\n",
    "        # frame is passed/drawn on instead of rgb_frame bc we draw on frame and then display it later using cv2.imshow\n",
    "\n",
    "\n",
    "        landmarks = results.pose_landmarks\n",
    "\n",
    "    print(landmarks[])\n",
    "\n",
    "\n",
    "    # Display: imshow opens a window named \"Pose Tracking\" that shows the current frame with the skelton overlay\n",
    "    cv2.imshow(\"Pose Tracking\", image)\n",
    "\n",
    "\n",
    "    # code to check if 'q' is pressed -> 'q' to quit/break loop\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "\n",
    "\n",
    "cap.release()  # frees webcam so other programs can use it\n",
    "cv2.destroyAllWindows()  # closes all openCV windows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61cd73e1",
   "metadata": {},
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
